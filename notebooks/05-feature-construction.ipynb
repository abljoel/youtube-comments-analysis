{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8038659-f21b-4866-926d-e0465c0b1134",
   "metadata": {},
   "source": [
    "# Constructing Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc48f7c-700d-4edc-bfc6-8a72a19deb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import warnings\n",
    "\n",
    "# Scientific and visual libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from emot import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Local Modules\n",
    "from youtube_analysis.paths import TRANSFORMED_DATA_DIR\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Various settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_colwidth\", 40)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a603171-ef22-4d67-a4af-669d5770699f",
   "metadata": {},
   "source": [
    "In Text analysis, itâ€™s really easy to extract new features from unstructured data. We could inspect any characteristic to do that: does the user comment contain foreign words, does the user make short comments, did the viewer update its comment ? For now we will only create two simple features for categorizing peoples that use emoticons and emojis in their comments.\r\n",
    "\r\n",
    "The code for that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2950d842-7766-4655-97c2-4b006841d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_emojis(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    for emo in UNICODE_EMOJI:\n",
    "        if emo in tokenized_text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def has_emoticons(text):\n",
    "    new_text = text\n",
    "    for ticon in EMOTICONS_EMO:\n",
    "        if ticon in new_text:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399eb25-b54a-4f18-832f-2fdd6c0eaa89",
   "metadata": {},
   "source": [
    "We apply these functions on original text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86131148-7874-4146-a043-accb0ca8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle(TRANSFORMED_DATA_DIR / \"sentiment_corpus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec1014e-ead8-4716-8e36-e4d60973ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"has_emojis\"] = corpus.text.apply(lambda t: has_emojis(t))\n",
    "corpus[\"has_emoticons\"] = corpus.text.apply(lambda t: has_emoticons(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32dab7b2-da6e-4d0f-96b0-b38542dc3211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>sent_class</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>has_emojis</th>\n",
       "      <th>has_emoticons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>2022-12-29 17:34:04+00:00</td>\n",
       "      <td>2022-12-29 17:34:04+00:00</td>\n",
       "      <td>194</td>\n",
       "      <td>Here are the timestamps. Please chec...</td>\n",
       "      <td>here are the timestamps   please che...</td>\n",
       "      <td>timestamps please check sponsors sup...</td>\n",
       "      <td>timestamps please check sponsor supp...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Dickinson</td>\n",
       "      <td>2023-11-19 10:59:46+00:00</td>\n",
       "      <td>2023-11-19 10:59:46+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Protein research is a major new brea...</td>\n",
       "      <td>protein research is a major new brea...</td>\n",
       "      <td>protein research major new breakthrough</td>\n",
       "      <td>protein research major new breakthrough</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Dickinson</td>\n",
       "      <td>2023-11-19 10:50:38+00:00</td>\n",
       "      <td>2023-11-19 10:50:38+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a good one.</td>\n",
       "      <td>this is a good one</td>\n",
       "      <td>good one</td>\n",
       "      <td>good one</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john g henderson</td>\n",
       "      <td>2023-11-18 03:47:08+00:00</td>\n",
       "      <td>2023-11-18 03:49:31+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>A very interesting conversation unti...</td>\n",
       "      <td>a very interesting conversation unti...</td>\n",
       "      <td>interesting conversation end answer ...</td>\n",
       "      <td>interesting conversation end answer ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.8960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arife dickerson</td>\n",
       "      <td>2023-11-17 20:49:24+00:00</td>\n",
       "      <td>2023-11-17 20:49:24+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>This chick is always in Bilderberg g...</td>\n",
       "      <td>this chick is always in bilderberg g...</td>\n",
       "      <td>chick always bilderberg group meetin...</td>\n",
       "      <td>chick always bilderberg group meetin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author              published_at                updated_at  \\\n",
       "0       Lex Fridman 2022-12-29 17:34:04+00:00 2022-12-29 17:34:04+00:00   \n",
       "1    John Dickinson 2023-11-19 10:59:46+00:00 2023-11-19 10:59:46+00:00   \n",
       "2    John Dickinson 2023-11-19 10:50:38+00:00 2023-11-19 10:50:38+00:00   \n",
       "3  john g henderson 2023-11-18 03:47:08+00:00 2023-11-18 03:49:31+00:00   \n",
       "4   arife dickerson 2023-11-17 20:49:24+00:00 2023-11-17 20:49:24+00:00   \n",
       "\n",
       "   likes                                     text  \\\n",
       "0    194  Here are the timestamps. Please chec...   \n",
       "1      0  Protein research is a major new brea...   \n",
       "2      0                      This is a good one.   \n",
       "3      0  A very interesting conversation unti...   \n",
       "4      0  This chick is always in Bilderberg g...   \n",
       "\n",
       "                              cleaned_text  \\\n",
       "0  here are the timestamps   please che...   \n",
       "1  protein research is a major new brea...   \n",
       "2                     this is a good one     \n",
       "3  a very interesting conversation unti...   \n",
       "4  this chick is always in bilderberg g...   \n",
       "\n",
       "                             filtered_text  \\\n",
       "0  timestamps please check sponsors sup...   \n",
       "1  protein research major new breakthrough   \n",
       "2                                 good one   \n",
       "3  interesting conversation end answer ...   \n",
       "4  chick always bilderberg group meetin...   \n",
       "\n",
       "                           lemmatized_text sent_class  sent_score  has_emojis  \\\n",
       "0  timestamps please check sponsor supp...   positive      0.9922           0   \n",
       "1  protein research major new breakthrough    neutral      0.0000           0   \n",
       "2                                 good one   positive      0.4404           0   \n",
       "3  interesting conversation end answer ...   negative     -0.8960           0   \n",
       "4  chick always bilderberg group meetin...    neutral      0.0000           0   \n",
       "\n",
       "   has_emoticons  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a40a8-f079-44c1-a08e-6aba0fa837b5",
   "metadata": {},
   "source": [
    "We will save it into a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7341d6f1-dd2e-474d-aaea-aa76ccceceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_pickle(TRANSFORMED_DATA_DIR / \"improved_sentiment_corpus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8af88-36bb-41f5-a4cc-66ed263882c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a5578-e6c6-448c-bf89-16dfa2f9a828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
