{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Raw Data From Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll dive into YouTube data to construct a NLP dataset from a YouTube channel. Our focus will be on a compelling episode of the Lex Friedman podcast featuring [astrobiologist Betül Kaçar](https://www.youtube.com/watch?v=NXU_M4030nE&ab_channel=LexFridman). \n",
    "\n",
    "Luckily for us, YouTube is full of freely-contributed user-generated text content. To achieve this goal on our target channel, we'll query YouTube Data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import warnings\n",
    "\n",
    "# Scientific and visual libraries\n",
    "import pandas as pd\n",
    "import googleapiclient.errors\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Various settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_colwidth\", 40)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First to kick off our analysis, we need to gather the raw comments from the chosen YouTube video. Leveraging the power of the YouTube API, our ETL process will efficiently collect valuable data for building a Pandas DataFrame.\n",
    "\n",
    "The next Python code below exemplifies the extraction function. Utilizing the googleapiclient library, the function seamlessly interacts with the YouTube API, allowing us to capture essential information such as author details, publication and update timestamps, like counts, and the textual content of each comment.\n",
    "\n",
    "The `fetch_youtube_comments` function requires your Youtube personal API key for authentication. It is implemented in the `data` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_analysis.data import fetch_youtube_comments\n",
    "import youtube_analysis.config as config\n",
    "\n",
    "\n",
    "def fetch_batch_data_from_video(vid, limit=3000):\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    api_key = config.YOUTUBE_API_KEY\n",
    "    try:\n",
    "        ytb_df = pd.DataFrame(\n",
    "            fetch_youtube_comments(\n",
    "                \"snippet\", vid, limit, api_service_name, api_version, api_key\n",
    "            ),\n",
    "            columns=[\"author\", \"published_at\", \"updated_at\", \"likes\", \"text\"],\n",
    "        )\n",
    "    except googleapiclient.errors.HttpError as e:\n",
    "        print(f\"Error {e.resp.status} occurred while fetching data:\\n{e.content}\")\n",
    "    return ytb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get and copy the target video ID on Youtube. Now we can use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_video_id = \"NXU_M4030nE\"\n",
    "lex_comments = fetch_batch_data_from_video(vid=lex_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>2022-12-29T17:34:04Z</td>\n",
       "      <td>2022-12-29T17:34:04Z</td>\n",
       "      <td>194</td>\n",
       "      <td>Here are the timestamps. Please chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Dickinson</td>\n",
       "      <td>2023-11-19T10:59:46Z</td>\n",
       "      <td>2023-11-19T10:59:46Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Protein research is a major new brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Dickinson</td>\n",
       "      <td>2023-11-19T10:50:38Z</td>\n",
       "      <td>2023-11-19T10:50:38Z</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a good one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john g henderson</td>\n",
       "      <td>2023-11-18T03:47:08Z</td>\n",
       "      <td>2023-11-18T03:49:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>A very interesting conversation unti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arife dickerson</td>\n",
       "      <td>2023-11-17T20:49:24Z</td>\n",
       "      <td>2023-11-17T20:49:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>This chick is always in Bilderberg g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author          published_at            updated_at  likes  \\\n",
       "0       Lex Fridman  2022-12-29T17:34:04Z  2022-12-29T17:34:04Z    194   \n",
       "1    John Dickinson  2023-11-19T10:59:46Z  2023-11-19T10:59:46Z      0   \n",
       "2    John Dickinson  2023-11-19T10:50:38Z  2023-11-19T10:50:38Z      0   \n",
       "3  john g henderson  2023-11-18T03:47:08Z  2023-11-18T03:49:31Z      0   \n",
       "4   arife dickerson  2023-11-17T20:49:24Z  2023-11-17T20:49:24Z      0   \n",
       "\n",
       "                                      text  \n",
       "0  Here are the timestamps. Please chec...  \n",
       "1  Protein research is a major new brea...  \n",
       "2                      This is a good one.  \n",
       "3  A very interesting conversation unti...  \n",
       "4  This chick is always in Bilderberg g...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do is save our corpus. To circumvent the need for repetitive hard-coding of lengthy paths and constant copy/pasting, I import my own `paths` module. I opt for saving in pickle format due to its convenience for Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_analysis.paths import RAW_DATA_DIR\n",
    "\n",
    "lex_comments.to_pickle(RAW_DATA_DIR / \"lex_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
